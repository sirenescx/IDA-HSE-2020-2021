{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHgmxWG_7lnE",
        "colab_type": "text"
      },
      "source": [
        "# Введение в анализ данных\n",
        "## НИУ ВШЭ, 2019-2020 учебный год\n",
        "\n",
        "### Домашнее задание №3\n",
        "\n",
        "Задание выполнил(а): Манахова Мария\n",
        "\n",
        "### Общая информация\n",
        "Дата выдачи: \n",
        "\n",
        "Дедлайн: \n",
        "\n",
        "### О задании\n",
        "\n",
        "В этом домашнем задании вы будете работать с линейной классификацией, попрактикуетесь на реальной задаче классификации текстов.\n",
        "\n",
        "Для решения этого домашнего задания намного удобнее будет использовать Colab, так как данных много.\n",
        "\n",
        "### Оценивание и штрафы\n",
        "\n",
        "За сдачу задания позже срока на итоговую оценку за задание накладывается штраф в размере 1 балл в день, но получить отрицательную оценку нельзя.\n",
        "\n",
        "__Внимание!__ Домашнее задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов.\n",
        "\n",
        "### Формат сдачи\n",
        "Загрузка файлов с решениями происходит в системе Anytask."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztx03xvr9T95",
        "colab_type": "text"
      },
      "source": [
        "### Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVrrwTJNjuDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VMchexbjjTh",
        "colab_type": "code",
        "outputId": "f94cd2ea-1bad-484c-d20a-8441f99f6b15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "# Датасет можно скачать здесь\n",
        "\n",
        "!wget https://www.dropbox.com/s/tg55q9mrziroyrs/train_subset.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-26 17:59:03--  https://www.dropbox.com/s/tg55q9mrziroyrs/train_subset.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/tg55q9mrziroyrs/train_subset.csv [following]\n",
            "--2020-04-26 17:59:03--  https://www.dropbox.com/s/raw/tg55q9mrziroyrs/train_subset.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uce60a0c76ada0f516e975d85e66.dl.dropboxusercontent.com/cd/0/inline/A2m57Tl9Pc7viFtozwIKvVdjiS4azOncyTrFtndZre-6px-nc2eRsjf7elLsxzsyEjuI5XAGbkU2-NPhAQ7XYhRTd-2dzfC0xBjkB0ZEVovYaSk84Pn674ICce3pfSoN9Fs/file# [following]\n",
            "--2020-04-26 17:59:03--  https://uce60a0c76ada0f516e975d85e66.dl.dropboxusercontent.com/cd/0/inline/A2m57Tl9Pc7viFtozwIKvVdjiS4azOncyTrFtndZre-6px-nc2eRsjf7elLsxzsyEjuI5XAGbkU2-NPhAQ7XYhRTd-2dzfC0xBjkB0ZEVovYaSk84Pn674ICce3pfSoN9Fs/file\n",
            "Resolving uce60a0c76ada0f516e975d85e66.dl.dropboxusercontent.com (uce60a0c76ada0f516e975d85e66.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uce60a0c76ada0f516e975d85e66.dl.dropboxusercontent.com (uce60a0c76ada0f516e975d85e66.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19213119 (18M) [text/plain]\n",
            "Saving to: ‘train_subset.csv.4’\n",
            "\n",
            "train_subset.csv.4  100%[===================>]  18.32M  37.0MB/s    in 0.5s    \n",
            "\n",
            "2020-04-26 17:59:04 (37.0 MB/s) - ‘train_subset.csv.4’ saved [19213119/19213119]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvXKae8q9nn-",
        "colab_type": "text"
      },
      "source": [
        "### Данные\n",
        "\n",
        "Мы имеем дело с данными с торговой платформы Avito.\n",
        "Для каждого товара представлены следующие параметры:\n",
        " - title\n",
        " - description\n",
        " - Category_name\n",
        " - Category\n",
        "\n",
        "Имеется информация об объектах 50 классов.\n",
        "Задача: по новым объектам (title, description) предсказать Category.\n",
        "(Очевидно, что параметр Category_name для предсказания классов использовать нельзя)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqEuoDhqNgoa",
        "colab_type": "code",
        "outputId": "4df23ecf-7dce-456b-fc3e-af3f9d82c46d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "data = pd.read_csv(\"train_subset.csv\", index_col='id')\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>Category_name</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>382220</th>\n",
              "      <td>Прихожая</td>\n",
              "      <td>В хорошем состоянии. Торг</td>\n",
              "      <td>Мебель и интерьер</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397529</th>\n",
              "      <td>Кордиант 215/55/16 Летние</td>\n",
              "      <td>Кордиант 215/55/16 Летние/\\n /\\nАртикул: 1737l...</td>\n",
              "      <td>Запчасти и аксессуары</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584569</th>\n",
              "      <td>Стол</td>\n",
              "      <td>Стол, 2 рабочих места . Стол серого цвета, в д...</td>\n",
              "      <td>Мебель и интерьер</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2513100</th>\n",
              "      <td>Комбинезон</td>\n",
              "      <td>Размер-42/44</td>\n",
              "      <td>Одежда, обувь, аксессуары</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1091886</th>\n",
              "      <td>Ветровка</td>\n",
              "      <td>На 2 года</td>\n",
              "      <td>Детская одежда и обувь</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             title  ... Category\n",
              "id                                  ...         \n",
              "382220                    Прихожая  ...       20\n",
              "397529   Кордиант 215/55/16 Летние  ...       10\n",
              "584569                        Стол  ...       20\n",
              "2513100                 Комбинезон  ...       27\n",
              "1091886                   Ветровка  ...       29\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg8iPp7fiwGh",
        "colab_type": "code",
        "outputId": "2903a0eb-ba15-44db-ebaa-9dcc84b759f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1hvzAMETU2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data[['title', 'description']].to_numpy()\n",
        "y = data['Category'].to_numpy()\n",
        "\n",
        "del data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMYU7zZw_cw-",
        "colab_type": "text"
      },
      "source": [
        "Сразу разделим выборку на train и test.\n",
        "Никакие данные из test для обучения использовать нельзя!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fia4_3vNprp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDR8LtTJUIGt",
        "colab_type": "code",
        "outputId": "99cbb2ce-256b-45da-9da6-71c5c9dd516f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "X_train[:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Сапоги 46 размер новые', 'Сапоги 46 размер новые'],\n",
              "       ['Светильники потолочный swarovski',\n",
              "        'светильники потолочные swarovski 6 штук , цена за штуку. В эксплуатации 2 года , продаются в связи со сменой интерьера в квартире'],\n",
              "       ['iPhone 7 plus 128GB Red красный в наличии',\n",
              "        '\\xa0/\\n/\\n Данная цена только для подписчиков Instagram: iQmac/\\n/\\n Новый красный айфон 7 Plus в наличии это элегантный и мощный смартфон, который готов в полной мере раскрыть новые возможности iOS 10. Аппарат с 4-ядерным процессором А10 и 3 ГБ ОЗУ с легкостью решает самые ресурсоемкие задачи, позволяя наслаждаться быстродействием «тяжелых» приложений и игр на 5,5-дюймовом дисплее. Аппарат получил экран, как у iPad Pro, так что картинка теперь соответствует кинематографическому стандарту.'],\n",
              "       ['Пион Ирис Ромашка рассада',\n",
              "        'Пион куст 500 р ( более 10 шт)/\\nСаженец/ корень 100р/\\nРастут у нас более 70 лет/\\nРозовые, бордовые и белые/\\nНа фото цветы 2018г/\\nП. Зубчаниновка/\\nлибо пл. Революции/\\nЕсть ирисы, ромашка, клубника, боярышник и ирга'],\n",
              "       ['Кофта', 'Состояние отличное']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-ZEdlEGAXTD",
        "colab_type": "text"
      },
      "source": [
        "### Токенизация (1 балл)\n",
        "\n",
        "\n",
        "Токенизация -- разбиение текста на мелкие части, которые можно обработать машинными методами.\n",
        "Можно использовать разные алгоритмы токенизации.\n",
        "Давайте пока остановимся на простом WordPunctTokenizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9VgNlZ1Qy3o",
        "colab_type": "code",
        "outputId": "6acda247-78cf-4918-b217-18166b9fb782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "\n",
        "tokenizer = WordPunctTokenizer()\n",
        "\n",
        "\n",
        "def preprocess(text: str) -> str:\n",
        "    return ' '.join(tokenizer.tokenize(text.lower()))\n",
        "\n",
        "\n",
        "text = 'Здраствуйте. Я, Кирилл. Хотел бы чтобы вы сделали игру, 3Д-экшон суть такова...'\n",
        "print(\"before:\", text,)\n",
        "print(\"after:\", preprocess(text),)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before: Здраствуйте. Я, Кирилл. Хотел бы чтобы вы сделали игру, 3Д-экшон суть такова...\n",
            "after: здраствуйте . я , кирилл . хотел бы чтобы вы сделали игру , 3д - экшон суть такова ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_RYBKC26o1X",
        "colab_type": "text"
      },
      "source": [
        "__Задание:__ Токенизируйте title и description в train и test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5WO-7tJUvbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(sample):\n",
        "  for i in range(sample.shape[0]):\n",
        "    for j in range(sample.shape[1]):\n",
        "      sample[i][j] = preprocess(sample[i][j])\n",
        "\n",
        "tokenize(X_train)\n",
        "tokenize(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kARGeJQwYTil",
        "colab_type": "code",
        "outputId": "6d43e849-b757-4b9a-92c0-d69859c6ab6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "X_train[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['сапоги 46 размер новые', 'сапоги 46 размер новые'],\n",
              "       ['светильники потолочный swarovski',\n",
              "        'светильники потолочные swarovski 6 штук , цена за штуку . в эксплуатации 2 года , продаются в связи со сменой интерьера в квартире'],\n",
              "       ['iphone 7 plus 128gb red красный в наличии',\n",
              "        '/ / данная цена только для подписчиков instagram : iqmac / / новый красный айфон 7 plus в наличии это элегантный и мощный смартфон , который готов в полной мере раскрыть новые возможности ios 10 . аппарат с 4 - ядерным процессором а10 и 3 гб озу с легкостью решает самые ресурсоемкие задачи , позволяя наслаждаться быстродействием « тяжелых » приложений и игр на 5 , 5 - дюймовом дисплее . аппарат получил экран , как у ipad pro , так что картинка теперь соответствует кинематографическому стандарту .'],\n",
              "       ['пион ирис ромашка рассада',\n",
              "        'пион куст 500 р ( более 10 шт )/ саженец / корень 100р / растут у нас более 70 лет / розовые , бордовые и белые / на фото цветы 2018г / п . зубчаниновка / либо пл . революции / есть ирисы , ромашка , клубника , боярышник и ирга'],\n",
              "       ['кофта', 'состояние отличное'],\n",
              "       ['1 - к квартира , 33 м² , 4 / 5 эт .',\n",
              "        'продаётся уютная , тёплая квартира в экологически - чистом районе города , рядом сосновый бор , всегда чистый воздух . дом 2004 г ., хорошие соседи , на площадке 2 - е квартиры , развитая инфраструктура , в шаговой доступности поликлиника , школа , тк « орбита », вещевой рынок . квартира в хорошем состоянии . подходит под ипотеку , долгов , обременений , перепланировке нет . в квартире натяжные потолки , в ванной комнате стены выполнены из влагостойких стеновых панелей . возможен обмен на квартиру в г . магнитогорске , торг .'],\n",
              "       ['платье новое 60 размера',\n",
              "        'платье 60 размера , новое , красивого темно синего цвета , из трикотажной ткани : вискоза 95 %, эластина 5 % . а - образного силуэта с рукавом 2 / 3 . длинна по спинке 113см .'],\n",
              "       ['ваз 2114 samara , 2007',\n",
              "        'продам ваз 2114 2007 г . в . в хорошем состоянии . / 2 владельца , птс оригинал . / машина в родной краске , в дтп никогда не была ,/ днище целое не ржавое . по ходовой нареканий нет , сел и поехал . / имеется музыка , сигнализация 2 комплекта ключей , птф , передние стеклоподъемники ./ небольшой торг при осмотре . / обмен не интересует .'],\n",
              "       ['наушники блутус',\n",
              "        'долго держат заряд 4 - 5 часов , можно и больше при средней громкости выжать из них . вкладыши .'],\n",
              "       ['пальто tommy hilfiger',\n",
              "        'состояние нового . промахнулась с размером . пальто до - 10 - 12 градусов . / возможна пересылка по почте']],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDnDSWwFDwFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert X_train[10][1] == 'продам иж планета 3 , 76 год , ( стоит на старом учёте , документы утеряны ) на ходу , хорошее состояние , все интересующие вопросы по телефону ( с родной коляской на 3 тысячи дороже ) . торга не будет .'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlIITUk0AsmS",
        "colab_type": "text"
      },
      "source": [
        "### BOW (1.5 балла)\n",
        "\n",
        "Один из традиционных подходов -- построение bag of words.\n",
        "\n",
        "Метод состоит в следующем:\n",
        "\n",
        " - Составить словарь самых часто встречающихся слов в train data\n",
        " - Для каждого примера из train посчитать, сколько раз каждое слово из словаря в нём встречается\n",
        "\n",
        "\n",
        " В sklearn есть CountVectorizer, но в этом задании его использовать нельзя."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMKUttDWIF92",
        "colab_type": "text"
      },
      "source": [
        "__Задание:__ Найдите k самых частых слов, отсортируйте их по убыванию частотности (k=10000)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEVE_bzkRBx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def get_vocabulary(sample, k):\n",
        "  c = Counter()\n",
        "  for i in range(sample.shape[0]):\n",
        "    for j in range(sample.shape[1]):\n",
        "      words = sample[i][j].split()\n",
        "      for word in words:\n",
        "        c[word] += 1\n",
        "\n",
        "  return np.array(c.most_common(k))[:, 0]\n",
        "  \n",
        "bow_vocabulary = get_vocabulary(X_train, 10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTs70ZxVbk0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert sorted(bow_vocabulary)[::200] == ['!', '12500', '270', '700', 'by', 'gh', 'michael', 'sonata', 'ø', 'аудиоподготовка', 'большим', 'веса', 'воспроизведения', 'габариты', 'гтд', 'джинсами', 'доступность', 'загрузки', 'зимней', 'использовался', 'квартала', 'коммуникации', 'кошки', 'лакированные', 'магазин', 'металл', 'мск', 'натуральным', 'носке', 'одному', 'отвечаем', 'пассат', 'плотно', 'покраску', 'постоянные', 'примеры', 'просьба', 'размещайте', 'репетитор', 'сантехник', 'сидения', 'современного', 'стала', 'схема', 'тон', 'удлиненная', 'фасад', 'цветами', 'шея', 'эту']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4awkhecbR9om",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_to_bow(text: str) -> np.array:\n",
        "    \"\"\"\n",
        "    Возвращает вектор, где для каждого слова из most_common\n",
        "    указано количество его употреблений\n",
        "    \"\"\" \n",
        "    bow = {}\n",
        "    for bow_word in bow_vocabulary:\n",
        "      bow[bow_word] = 0\n",
        "    words = text.split()\n",
        "    for word in words:\n",
        "      if word in bow:\n",
        "        bow[word] += 1\n",
        "\n",
        "    return np.fromiter(bow.values(), dtype=int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZnJT2JbdXA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert np.allclose(np.where(text_to_bow(\"сдаётся уютный , тёплый гараж для стартапов в ml\") != 0)[0],\n",
        "                   np.array([   1,    4,   12,  565,  866, 1601, 2539, 4063])\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR_D8Fn4pudv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def items_to_bow(items: np.array) -> np.array:\n",
        "    \"\"\" Для каждого товара возвращает вектор его bow \"\"\"\n",
        "    # Давайте для начала попробуем строить bow только из description товара\n",
        "    # assert ниже написан для bow из description\n",
        "    bow = []\n",
        "    for item in items:\n",
        "      bow.append(text_to_bow(item[1]))\n",
        "\n",
        "    return np.array(bow)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKdfMqbIetPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert np.allclose(np.where(items_to_bow([X_train[42]])[0] != 0),\n",
        "                   np.array([   0, 1, 2, 5, 6, 7, 12, 27, 41, 49, 110,\n",
        "                                189,  208,  221, 2032, 3052, 7179, 9568]),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p6rbAS3kNfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_bow = items_to_bow(X_train)\n",
        "X_test_bow = items_to_bow(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJVLS8Fs3CeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJoXiCWI7VF5",
        "colab_type": "text"
      },
      "source": [
        "### Логистическая регрессия и SVC (1 балл)\n",
        "\n",
        "\n",
        "Теперь описание каждого товара представлено, как точка в многомерном пространстве.\n",
        "Очень важно запомнить эту идею: дальше мы будем рассматривать разные способы перехода от текста к точке в пространстве.\n",
        "\n",
        "Для BOW каждое измерение в пространстве -- какое-то слово.\n",
        "Мы предполагаем, что текст описывается набором каких-то популярных слов, которые в нём встречаются, а близкие по смыслу тексты будут использовать одинаковые слова.\n",
        "\n",
        "Обучите логистическую регрессию и SVC с базовыми параметрами.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky3HV1rTSS9L",
        "colab_type": "code",
        "outputId": "33cb33ce-6efc-4578-9545-53fc645d3ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "bow_model = LogisticRegression(max_iter=100).fit(X_train_bow, y_train)\n",
        "print(accuracy_score(bow_model.predict(X_test_bow), y_test))\n",
        "\n",
        "assert accuracy_score(bow_model.predict(X_test_bow), y_test) > 0.7"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7011111111111111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c46ZT0lvF6T",
        "colab_type": "code",
        "outputId": "5f2f58bc-f716-4eea-a9be-7bd43045f197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "bow_model = LinearSVC(max_iter=70).fit(X_train_bow, y_train)\n",
        "print(accuracy_score(bow_model.predict(X_test_bow), y_test))\n",
        "\n",
        "assert accuracy_score(bow_model.predict(X_test_bow), y_test) > 0.68"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6848888888888889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lpMkC7PjEME",
        "colab_type": "text"
      },
      "source": [
        "Качество на логистической регрессии – 0.701, на линейной классификации методом опорных векторов – 0.685."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwKE57YZ1Hzn",
        "colab_type": "text"
      },
      "source": [
        "### Модификация признаков (0.5 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewMlxQezL6Ax",
        "colab_type": "text"
      },
      "source": [
        "Добавьте title товара в bow с произвольным весом, как изменится качество?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evqKo1r5L5BO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def items_to_bow_title(items: np.array) -> np.array:\n",
        "    bow = []\n",
        "    for item in items:\n",
        "      bow.append(text_to_bow(item[0]))\n",
        "    return np.array(bow)\n",
        "\n",
        "X_train_bow_with_title = X_train_bow + items_to_bow_title(X_train) * 2\n",
        "X_test_bow_with_title = X_test_bow + items_to_bow_title(X_test) * 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Mf8BezE66i1",
        "colab_type": "code",
        "outputId": "f5003975-6337-43d0-ab38-9bb434c8e913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "bow_model_with_title = LogisticRegression(max_iter=100).fit(X_train_bow_with_title, y_train)\n",
        "print(accuracy_score(bow_model_with_title.predict(X_test_bow_with_title), y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7944444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyIyxd5tio5l",
        "colab_type": "code",
        "outputId": "f33bd9ec-d3f2-4da1-e443-ff0487ba9985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "bow_model_with_title = LinearSVC(max_iter=70).fit(X_train_bow_with_title, y_train)\n",
        "print(accuracy_score(bow_model_with_title.predict(X_test_bow_with_title), y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7621111111111111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB9EfeA6Yzdc",
        "colab_type": "text"
      },
      "source": [
        "После добавления title в bow с весом 2 качество модели улучшилось и на логистической регрессии – 0.794 (на 0.093), и на линейной классификации методом опорных векторов – 0.762 (на 0.077). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db4TyqzxMnby",
        "colab_type": "text"
      },
      "source": [
        "Нормализуйте данные (`sklearn.preprocessing.normalize`) перед обучением. Что станет с качеством и почему?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7ZSVPUm8YkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "X_train_bow_normalized = preprocessing.normalize(X_train_bow_with_title)\n",
        "X_test_bow_normalized = preprocessing.normalize(X_test_bow_with_title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlwneX-O8dHa",
        "colab_type": "code",
        "outputId": "6169ec8c-f7a0-41c8-93a8-b066da391e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "bow_model_normalized = LogisticRegression(max_iter=100).fit(X_train_bow_normalized, y_train)\n",
        "print(accuracy_score(bow_model_normalized.predict(X_test_bow_normalized), y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7041111111111111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8rVy6q1Mn4J",
        "colab_type": "code",
        "outputId": "ebd4e494-10d3-48d4-8bcf-be9db8b44529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bow_model_normalized = LinearSVC(max_iter=70).fit(X_train_bow_normalized, y_train)\n",
        "print(accuracy_score(bow_model_normalized.predict(X_test_bow_normalized), y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8072222222222222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0t8or7eZ-oS",
        "colab_type": "text"
      },
      "source": [
        "После нормализации данных качество на линейной регрессии упало по сравнению с не нормализованными данными – 0.704 (на 0.09), качество обучения с использованием линейной классификации методом опорных векторов возросло – 0.807 (на 0.045). Тем не менее, по сравнению с исходными данными (без учета title) качество на обеих моделях все еще лучше."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvCAL3qGDByj",
        "colab_type": "text"
      },
      "source": [
        "### mystem (0.5) балла\n",
        "\n",
        "Попробуйте обучиться, используя токенизатор mystem. Сравните качество."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz38TqqRDY6-",
        "colab_type": "code",
        "outputId": "ee390444-d1d4-4e66-b271-4629984d0c30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!cp mystem /bin"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-26 17:11:10--  http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
            "Resolving download.cdn.yandex.net (download.cdn.yandex.net)... 5.45.205.244, 5.45.205.243, 5.45.205.242, ...\n",
            "Connecting to download.cdn.yandex.net (download.cdn.yandex.net)|5.45.205.244|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://cache-mskm902.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz [following]\n",
            "--2020-04-26 17:11:10--  http://cache-mskm902.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
            "Resolving cache-mskm902.cdn.yandex.net (cache-mskm902.cdn.yandex.net)... 5.45.220.12, 2a02:6b8:0:2002::13\n",
            "Connecting to cache-mskm902.cdn.yandex.net (cache-mskm902.cdn.yandex.net)|5.45.220.12|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16457938 (16M) [application/octet-stream]\n",
            "Saving to: ‘mystem-3.0-linux3.1-64bit.tar.gz’\n",
            "\n",
            "mystem-3.0-linux3.1 100%[===================>]  15.70M  30.8MB/s    in 0.5s    \n",
            "\n",
            "2020-04-26 17:11:11 (30.8 MB/s) - ‘mystem-3.0-linux3.1-64bit.tar.gz’ saved [16457938/16457938]\n",
            "\n",
            "mystem\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60oQ-6UgDcLF",
        "colab_type": "code",
        "outputId": "a64b37a3-e559-47ff-9f95-7a161dd027ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "pip install git+https://github.com/nlpub/pymystem3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/nlpub/pymystem3\n",
            "  Cloning https://github.com/nlpub/pymystem3 to /tmp/pip-req-build-zmmdo5v_\n",
            "  Running command git clone -q https://github.com/nlpub/pymystem3 /tmp/pip-req-build-zmmdo5v_\n",
            "Requirement already satisfied (use --upgrade to upgrade): pymystem3==0.2.0 from git+https://github.com/nlpub/pymystem3 in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pymystem3==0.2.0) (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.2.0) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.2.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.2.0) (2020.4.5.1)\n",
            "Building wheels for collected packages: pymystem3\n",
            "  Building wheel for pymystem3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymystem3: filename=pymystem3-0.2.0-cp36-none-any.whl size=9921 sha256=8d4425f01795e916d2436a76c99863fb5bb673d5b64eded74d4e82795b66d987\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-blctvvj1/wheels/7d/75/c2/216a594291dee680749ce12c60d16125cfe1f363059e7163dc\n",
            "Successfully built pymystem3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGvNHfVsDfhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pymystem3 import Mystem"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge3uOgG8pftT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eRzP8_Xsvn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mystem = Mystem()\n",
        "\n",
        "def mystem_preprocess(text: str) -> str:\n",
        "    return ' '.join(mystem.lemmatize(text.lower()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOfpKqLdlJax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lemmatize(sample):\n",
        "  for i in range(sample.shape[0]):\n",
        "    for j in range(sample.shape[1]):\n",
        "      sample[i][j] = mystem_preprocess(sample[i][j])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bux_zH9s57j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatize(X_train_m)\n",
        "lemmatize(X_test_m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OC8MbyskuTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bow_vocabulary_m = get_vocabulary(X_train_m, 10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVMFqxnjt26c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_to_bow_m(text: str, bow_vocabulary) -> np.array:\n",
        "    bow = {}\n",
        "    for bow_word in bow_vocabulary:\n",
        "      bow[bow_word] = 0\n",
        "    words = text.split()\n",
        "    for word in words:\n",
        "      if word in bow:\n",
        "        bow[word] += 1\n",
        "\n",
        "    return np.fromiter(bow.values(), dtype=int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htUWrLULuuFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def items_to_bow_m(items: np.array, bow_vocabulary) -> np.array:\n",
        "    bow = []\n",
        "    for item in items:\n",
        "      bow.append(text_to_bow_m(item[1], bow_vocabulary))\n",
        "\n",
        "    return np.array(bow)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C05VJIYevLCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_m_bow = items_to_bow_m(X_train_m, bow_vocabulary_m)\n",
        "X_test_m_bow = items_to_bow_m(X_test_m, bow_vocabulary_m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmXGbSCtyUaC",
        "colab_type": "code",
        "outputId": "c95be89a-f3eb-4fdc-aa8d-642c1c7b6876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "bow_model_m = LogisticRegression(max_iter=100).fit(X_train_m_bow, y_train_m)\n",
        "print(accuracy_score(bow_model_m.predict(X_test_m_bow), y_test_m))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7298888888888889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qClk4ra7qpod",
        "colab_type": "code",
        "outputId": "e4b98638-fefa-4840-aa71-290d3a7b0e76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "bow_model_m = LinearSVC(max_iter=70).fit(X_train_m_bow, y_train_m)\n",
        "print(accuracy_score(bow_model_m.predict(X_test_m_bow), y_test_m))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7072222222222222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2zzx9XujxxO",
        "colab_type": "text"
      },
      "source": [
        "Качество на логистической регресси – 0.73, на линейной классификации методом опорных векторов – 0.707."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL22TOJnekTw",
        "colab_type": "text"
      },
      "source": [
        "При использовании токенизатора mystem качество по сравнению с использованием токенизатора WordPunctTokenizer возросло и на логистической регрессии (на 0.029), и на линейной классификации методом опорных векторов (на 0.022)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXbsPtpfoB7m",
        "colab_type": "text"
      },
      "source": [
        "### TF-IDF (1.5 балла)\n",
        "\n",
        "Не все слова полезны одинаково, давайте попробуем [взвесить](http://tfidf.com/) их, чтобы отобрать более полезные.\n",
        "\n",
        "\n",
        "> TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
        "> \n",
        "> IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
        "\n",
        "\n",
        "В sklearn есть TfidfVectorizer, но в этом задании его использовать нельзя."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yIeoic7o3ES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Давайте для простоты считать один tf-idf для title и description.\n",
        "# Для каждого слова из bow_vocabulary нужно посчитать\n",
        "# в тексте скольких товаров встретилось это слово\n",
        "\n",
        "def count(sample, vocabulary):\n",
        "  vocabulary_count = {}\n",
        "  for word in vocabulary:\n",
        "    vocabulary_count[word] = 0\n",
        "\n",
        "  for i in range(sample.shape[0]):\n",
        "      words = set(' '.join([sample[i][0], sample[i][1]]).split())\n",
        "      for word in words:\n",
        "        if word in vocabulary_count:\n",
        "          vocabulary_count[word] += 1\n",
        "\n",
        "  return vocabulary_count\n",
        "\n",
        "count_dict = count(X_train, bow_vocabulary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnycemmhVkAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_idf(count_dict, total_number_of_documents) -> np.array:\n",
        "  idf_array = []\n",
        "  for term in count_dict:\n",
        "    idf_array.append(np.log(total_number_of_documents / count_dict[term]))\n",
        "\n",
        "  return np.array(idf_array)\n",
        "\n",
        "idf = get_idf(count_dict, X_train.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjeHBCxeqxib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tf(text, vocabulary):\n",
        "  words = text.split()\n",
        "  frequences = Counter()\n",
        "  for word in words:\n",
        "    frequences[word] += 1\n",
        "\n",
        "  tf_array = []\n",
        "  for term in vocabulary:\n",
        "    if term in words:\n",
        "      tf_array.append(frequences[term] / len(set(words)))\n",
        "    else:\n",
        "      tf_array.append(0)\n",
        "\n",
        "  return np.array(tf_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bnLDBaPX2nr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_to_tfidf(text: str) -> np.array:\n",
        "    \"\"\"\n",
        "    Возвращает вектор, где для каждого слова из most_common\n",
        "    указан tf-idf\n",
        "    \"\"\"\n",
        "    tf = get_tf(text, bow_vocabulary)\n",
        "    tfidf = []\n",
        "\n",
        "    for i in range(idf.shape[0]):\n",
        "      tfidf.append(idf * tf[i])\n",
        "\n",
        "    return np.array(tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nnuk6yLbgaav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def items_to_tfidf(items: np.array) -> np.array:\n",
        "    tfidf = []\n",
        "    for item in items:\n",
        "      tfidf.append(text_to_tfidf(' '.join([item[0], item[1]])))\n",
        "\n",
        "    return np.array(tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21hfxScXjMRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_tfidf = items_to_tfidf(X_train)\n",
        "X_test_tfidf = items_to_tfidf(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvL9BH7DsJrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Нормализуйте данные\n",
        "X_train_tfidf = preprocessing.normalize(X_train_tfidf)\n",
        "X_test_tfidf = preprocessing.normalize(X_test_tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YFA-8kE1RHk",
        "colab_type": "text"
      },
      "source": [
        "### Модели на TF-IDF признаках (1 балл)\n",
        "\n",
        "Обучите логистическую регрессию и SVC, оцените качество (accuracy_score)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ULrXsF1m5sU",
        "colab_type": "code",
        "outputId": "35dcde0a-09f5-46f8-cebe-22727f01cb77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "bow_model = LogisticRegression(max_iter=100).fit(X_train_tfidf, y_train)\n",
        "print(accuracy_score(bow_model.predict(X_test_tfidf), y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7653333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8Q_HrasTsOj",
        "colab_type": "code",
        "outputId": "c8c8b384-bd0f-4718-82f8-8bc870cdaf54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bow_model = LinearSVC(max_iter=70).fit(X_train_tfidf, y_train)\n",
        "print(accuracy_score(bow_model.predict(X_test_tfidf), y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8067777777777778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPxSDJ91laXk",
        "colab_type": "text"
      },
      "source": [
        "По сравнению с исходным качество возросло и на логистической регрессии – 0.765 (на 0.064), и на линейной классификации методом опорных векторов – 0.807 (на 0.12)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFdy3lUFDsOr",
        "colab_type": "text"
      },
      "source": [
        "### Hashing Vectorizer (0.5 балла)\n",
        "\n",
        "Попробуйте использовать `sklearn.feature_extraction.text.HashingVectorizer` для векторизации текстов.\n",
        "Обязательно оцените качество работы алгоритмов классификации с использованием новой векторизации."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y666HTrqDq1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OeRSi8u3FFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def list_from_data(data):\n",
        "  data_list = []\n",
        "  for i in range(data.shape[0]):\n",
        "    data_list.append(' '.join([data[i][0], data[i][1]]))\n",
        "\n",
        "  return data_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EVfHPvj8FRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_hv, X_test_hv, y_train_hv, y_test_hv = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2lbhJKX7xG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "vectorizer = HashingVectorizer()\n",
        "X_train_hv = vectorizer.fit_transform(list_from_data(X_train_hv))\n",
        "X_test_hv = vectorizer.fit_transform(list_from_data(X_test_hv))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kf2Z4505ohT",
        "colab_type": "code",
        "outputId": "5d8a72f9-5b82-412e-cec7-9d008b681671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "hv_model = LinearSVC(max_iter=70).fit(X_train_hv, y_train_hv)\n",
        "print(accuracy_score(hv_model.predict(X_test_hv), y_test_hv))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8245555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3YVhJp156Hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hv_model = LogisticRegression(max_iter=100).fit(X_train_hv, y_train_hv)\n",
        "print(accuracy_score(hv_model.predict(X_test_hv), y_test_hv))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUrkPm8tmyYx",
        "colab_type": "text"
      },
      "source": [
        "Качество на линейной классификации методом опорных векторов возросло по сравнению со всеми предыдущими алгоритмами и их модификациями – 0.825, качество на логистической регрессии также показало неплохой результат."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQZ61xSsTpZI",
        "colab_type": "text"
      },
      "source": [
        "### Word Vectors (1 балл)\n",
        "\n",
        "Давайте попробуем другой подход -- кажому слову сопоставим какой-то эмбеддинг (вектор).\n",
        "\n",
        "Вектора будут небольшой размерности. Таким образом мы снизим количество параметров в модели.\n",
        "\n",
        "Вектора мы возьмём уже готовые (обученные на текстах их интернета), так что наша модель будет знать некоторую дополнительную информацию о внешнем мире."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T38J27NcYGx5",
        "colab_type": "code",
        "outputId": "e256eb4a-ec66-4310-c881-b0974ce9d9e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!wget https://www.dropbox.com/s/0x7oxso6x93efzj/ru.tar.gz"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-26 18:10:51--  https://www.dropbox.com/s/0x7oxso6x93efzj/ru.tar.gz\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/0x7oxso6x93efzj/ru.tar.gz [following]\n",
            "--2020-04-26 18:10:51--  https://www.dropbox.com/s/raw/0x7oxso6x93efzj/ru.tar.gz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc5c546df22557a9302470bd8af.dl.dropboxusercontent.com/cd/0/inline/A2me129Rph9v5Ay3z2GQMjy9fCfT6SqX63eANWHnUtLg5yx_ifSjDqdHnVmQ93R9jCCU2CrtAvi_MFclDRfp8Tr3GNzU2k8U8xz3Ou1MjRU9zw/file# [following]\n",
            "--2020-04-26 18:10:52--  https://ucc5c546df22557a9302470bd8af.dl.dropboxusercontent.com/cd/0/inline/A2me129Rph9v5Ay3z2GQMjy9fCfT6SqX63eANWHnUtLg5yx_ifSjDqdHnVmQ93R9jCCU2CrtAvi_MFclDRfp8Tr3GNzU2k8U8xz3Ou1MjRU9zw/file\n",
            "Resolving ucc5c546df22557a9302470bd8af.dl.dropboxusercontent.com (ucc5c546df22557a9302470bd8af.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to ucc5c546df22557a9302470bd8af.dl.dropboxusercontent.com (ucc5c546df22557a9302470bd8af.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/A2m3R9JCs16BCMmv9jGVpXV0AXRZJKx9tLc3-RZdevKYKS9SaWXHwKhhGN_GXQvr4vLrnpE_PDmeK63O_ouh6SpBsqGIK5azDBqwvFuNiaLuuY6AXvKDGcNCNU_4Qh5-PBrbmGTCtc0eKgn3QYFOXOUY9ov53DqZhX3FgXxrqoYc1cNcj2x3wOIP7hbprWwrcMWgjoTxVONy3cx0pcJjpJmnPmwE1Jq7gbcCsS63gTFa1YKNntL8fy16NhFyhEL9n65ff28pvF3NF7_Pij78HKID-YzROld67TCI6CO_aAcIc-S0xBbl_IN-6YYHmfCn8DrMadw4P4cnngedb6t2P9Ej/file [following]\n",
            "--2020-04-26 18:10:53--  https://ucc5c546df22557a9302470bd8af.dl.dropboxusercontent.com/cd/0/inline2/A2m3R9JCs16BCMmv9jGVpXV0AXRZJKx9tLc3-RZdevKYKS9SaWXHwKhhGN_GXQvr4vLrnpE_PDmeK63O_ouh6SpBsqGIK5azDBqwvFuNiaLuuY6AXvKDGcNCNU_4Qh5-PBrbmGTCtc0eKgn3QYFOXOUY9ov53DqZhX3FgXxrqoYc1cNcj2x3wOIP7hbprWwrcMWgjoTxVONy3cx0pcJjpJmnPmwE1Jq7gbcCsS63gTFa1YKNntL8fy16NhFyhEL9n65ff28pvF3NF7_Pij78HKID-YzROld67TCI6CO_aAcIc-S0xBbl_IN-6YYHmfCn8DrMadw4P4cnngedb6t2P9Ej/file\n",
            "Reusing existing connection to ucc5c546df22557a9302470bd8af.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2399456034 (2.2G) [application/octet-stream]\n",
            "Saving to: ‘ru.tar.gz’\n",
            "\n",
            "ru.tar.gz           100%[===================>]   2.23G  55.5MB/s    in 43s     \n",
            "\n",
            "2020-04-26 18:11:36 (53.3 MB/s) - ‘ru.tar.gz’ saved [2399456034/2399456034]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfse4xVbgMIr",
        "colab_type": "code",
        "outputId": "6a9674cc-a8e0-4286-a7b7-3f5aa14dd372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!tar -xzvf ru.tar.gz"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ru.bin\n",
            "ru.vec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy2TXmQ2jZSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from gensim.models.wrappers import FastText\n",
        "\n",
        "\n",
        "model = FastText.load_fasttext_format('ru.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H49QR_jhjmCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Эмбеддинг предложения -- сумма эмбеддингов токенов\n",
        "\n",
        "def sentence_embedding(sentence: str) -> np.array:\n",
        "    \"\"\"\n",
        "    Складывает вектора токенов строки sentence\n",
        "    \"\"\"\n",
        "\n",
        "    embedding_dim = model['кек'].shape[0]\n",
        "    features = np.zeros([embedding_dim], dtype='float32')\n",
        "    \n",
        "    for word in sentence.split():\n",
        "        if word in model:\n",
        "            features += model[word]\n",
        "    \n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj6U_hjtlllV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert np.allclose(sentence_embedding('сдаётся уютный , тёплый гараж для стартапов в ml')[::50],\n",
        "                   np.array([ 0.08189847,  0.07249198, -0.15601222,  0.03782297,  0.09215296, -0.23092946]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWP36RWFPoID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Обучите логистическую регрессию и SVM\n",
        "# Оцените качество (accuracy_score)\n",
        "X_train_e, X_test_e, y_train_e, y_test_e = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuHoWikwPvuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def items_to_sentence_embedding(items: np.array):\n",
        "  sentence_embeddings = []\n",
        "  for item in items:\n",
        "    sentence_embeddings.append(sentence_embedding(' '.join([item[0], item[1]])))\n",
        "\n",
        "  return sentence_embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1j9VenfQWGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_e = items_to_sentence_embedding(X_train_e)\n",
        "X_test_e = items_to_sentence_embedding(X_test_e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkZNCE8HQeLq",
        "colab_type": "code",
        "outputId": "30af2f8c-ba32-4019-bef7-b62ef937dcd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model_e = LinearSVC(max_iter=70).fit(X_train_e, y_train_e)\n",
        "print(accuracy_score(model_e.predict(X_test_e), y_test_e))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4816666666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aut17TGEVu0Y",
        "colab_type": "code",
        "outputId": "53e771e8-d19f-4be8-d8db-4b7836d320c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "model_e = LogisticRegression(max_iter=100).fit(X_train_e, y_train_e)\n",
        "print(accuracy_score(model_e.predict(X_test_e), y_test_e))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5008888888888889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnAmTjvTta3o",
        "colab_type": "text"
      },
      "source": [
        "Качество на обеих моделях сильно хуже, чем при использовании других подходов, логистическая регрессия – 0.5, линейная классификаци методом опорных векторов – 0.481)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVEdlFostSnX",
        "colab_type": "text"
      },
      "source": [
        "### Что дальше?\n",
        "\n",
        "Решение каждого пункта 1 балл:\n",
        "\n",
        "1. N-Gram модели текстовой классификации\n",
        "\n",
        "2. Обучиться на полных данных (контест на kaggle)\n",
        "\n",
        "3. Поработать с другими эмбеддингами (word2vec, GloVe).\n",
        "\n",
        "4. Использовать Vowpal Wabbit вместо sklearn.\n",
        "\n",
        "5. Другие способы токенизации (pymorphy2, spaCy)\n",
        "\n",
        "\n",
        "Снабжайте код пояснениями и графиками.\n",
        "Обязательно необходимо написать вывод по каждому пункту, который вы реализуете."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyIh2PN3udhD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "da3771b2-9f44-4a21-ce26-f7d87b67d585"
      },
      "source": [
        "pip install pymorphy2"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.9MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 28.6MB/s \n",
            "\u001b[?25hInstalling collected packages: dawg-python, pymorphy2-dicts, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_LF9UW_uLZa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "99d96470-faaa-4d87-846a-ca35f5cf7abc"
      },
      "source": [
        "pip install -U pymorphy2-dicts-ru"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2-dicts-ru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9b/358faaff410f65a4ad159275e897b5956dcb20576c5b8e764b971c1634d7/pymorphy2_dicts_ru-2.4.404381.4453942-py2.py3-none-any.whl (8.0MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0MB 9.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pymorphy2-dicts-ru\n",
            "Successfully installed pymorphy2-dicts-ru-2.4.404381.4453942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIw1zx-nuYfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pymorphy2\n",
        "from pymorphy2.tokenizers import simple_word_tokenize\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SocdJZjfukJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pymorphy_preprocess(text: str) -> str:\n",
        "    return ' '.join(simple_word_tokenize(text.lower()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiNKlrHiv21z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(sample):\n",
        "  for i in range(sample.shape[0]):\n",
        "    for j in range(sample.shape[1]):\n",
        "      sample[i][j] = pymorphy_preprocess(sample[i][j])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNP0fLgJv9Wn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTA2uWBJwDkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenize(X_train_p)\n",
        "tokenize(X_test_p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK4-U0bowIJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bow_vocabulary_p = get_vocabulary(X_train_p, 10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3ISqxRnxY13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_p_bow = items_to_bow_m(X_train_p, bow_vocabulary_p)\n",
        "X_test_p_bow = items_to_bow_m(X_test_p, bow_vocabulary_p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnwm1tOqx1ku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "65d50b1b-4d09-4c8c-df35-296e420de3f3"
      },
      "source": [
        "model_p = LinearSVC(max_iter=70).fit(X_train_p_bow, y_train_p)\n",
        "print(accuracy_score(model_p.predict(X_test_p_bow), y_test_p))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_uWVoRL07r2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "655f69c4-f264-4822-c6d0-437d4da3fa69"
      },
      "source": [
        "model_e = LogisticRegression(max_iter=100).fit(X_train_e, y_train_e)\n",
        "print(accuracy_score(model_e.predict(X_test_e), y_test_e))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5008888888888889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EupCbQWG1QfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}